# Advanced Machine Learning üöÄ

Welcome to my **Advanced Machine Learning** repository.

This repo is dedicated to my learning journey in Machine Learning, covering concepts from intermediate to advanced levels with hands-on implementations.  

---

## üìå Contents
- **üìñ Theory Notes** ‚Äì Key ML concepts explained  
- **üßë‚Äçüíª Python Implementations** ‚Äì Code for algorithms and techniques  
- **üìä Projects** ‚Äì End-to-end ML projects with datasets  
- **üõ†Ô∏è Utilities** ‚Äì Helper scripts and tools  

---

# üìö Machine Learning Course (Mirza Yasir Abdullah Baig)

This repository contains a structured learning path for mastering **Machine Learning** step by step.  
It follows a well-defined sequence starting from the basics to advanced ML topics with intuition, math, and code implementations.

---

## üìÇ Folder Structure

### 1. Introduction to Machine Learning
- What is Machine Learning?  
- AI vs ML vs DL for Beginners  
- Types of Machine Learning  
- Batch ML (Offline vs Online)  
- Online Machine Learning  
- Instance-Based vs Model-Based Learning  
- Challenges in Machine Learning  
- Applications of Machine Learning  
- ML Development Life Cycle (MLDLC)  
- Data Engineer vs Analyst vs Scientist vs ML Engineer  

---

### 2. ML Setup & Tools
- What are Tensors  
- Installing Anaconda, Jupyter, Colab  
- End-to-End Toy Project  

---

### 3. Data Handling
- Working with CSV files  
- Working with JSON/SQL  
- Fetching Data from API  
- Web Scraping for Data  

---

### 4. Exploratory Data Analysis (EDA)
- Understanding Your Data  
- EDA with Univariate Analysis  
- EDA with Bivariate & Multivariate Analysis  
- Pandas Profiling  

---

### 5. Feature Engineering
- What is Feature Engineering  
- Feature Scaling ‚Äì Standardization  
- Feature Scaling ‚Äì Normalization  
- Encoding Categorical Data (Ordinal, Label Encoding)  
- One-Hot Encoding  
- Column Transformer in Sklearn  
- Machine Learning Pipelines A‚ÄìZ  
- Function Transformer (Log, Reciprocal, Square Root)  
- Power Transformer (Box-Cox, Yeo-Johnson)  
- Binning & Binarization  
- Handling Mixed Variables  
- Handling Date & Time Variables  

---

### 6. Handling Missing Data
- Complete Case Analysis  
- Simple Imputer (Numerical)  
- Categorical Imputation (Most Frequent, Missing Category)  
- Missing Indicator, Random Sample Imputation  
- KNN Imputer, Multivariate Imputation  
- MICE Algorithm (Iterative Imputer)  

---

### 7. Outliers
- What are Outliers  
- Z-Score Method  
- IQR Method  
- Percentile Method (Winsorization)  

---

### 8. Dimensionality Reduction
- Curse of Dimensionality  
- PCA Part 1 (Geometric Intuition)  
- PCA Part 2 (Maths & Solution)  
- PCA Part 3 (Code Example & Visualization)  

---

### 9. Regression Models
- Simple Linear Regression (Intuition + Code + Maths)  
- Regression Metrics (MSE, RMSE, R¬≤)  
- Multiple Linear Regression (Intuition, Maths, Code)  
- Gradient Descent (Scratch + Animation + Variants)  
- Polynomial Regression  
- Bias-Variance Tradeoff (Overfitting/Underfitting)  
- Ridge Regression (All Parts)  
- Lasso Regression + Sparsity  
- ElasticNet Regression  

---

### 10. Classification Models
- Logistic Regression (All Parts: Sigmoid, Loss, Gradient, etc.)  
- Confusion Matrix, Accuracy, Type I/II Errors  
- Precision, Recall, F1 Score  
- Softmax Regression  
- Non-Linear Logistic Regression  
- Logistic Regression Hyperparameters  

---

### 11. Decision Trees & Ensembles
- Decision Trees (Entropy, Gini, Info Gain)  
- Regression Trees  
- Decision Tree Visualization (dtreeviz)  
- Ensemble Learning Introduction  
- Voting Ensemble (Classification + Regression)  
- Bagging (All Parts)  
- Random Forest (Intuition, Parameters, Tuning, OOB, Feature Importance)  
- AdaBoost (All Parts)  
- Bagging vs Boosting  
- Gradient Boosting (Regression, Classification, Maths)  
- Stacking & Blending Ensembles  

---

### 12. Clustering
- K-Means (Intuition, Code, From Scratch)  
- Agglomerative Hierarchical Clustering  
- DBSCAN Clustering  

---

### 13. Other Algorithms
- K-Nearest Neighbors (KNN)  
- Linear Regression Assumptions  
- Support Vector Machines (Hard Margin, Soft Margin, Kernel Trick)  
- Naive Bayes (All Parts)  

---

### 14. Advanced ML Topics
- XGBoost (Intro, Regression, Classification, Maths)  
- Imbalanced Data (Undersampling, Oversampling, SMOTE)  
- Hyperparameter Tuning (Optuna, Bayesian Optimization)  
- ROC Curve & AUC  

---

## üöÄ How to Use
1. Navigate through the folders in order.  
2. Each topic contains **notes, code examples, and practice exercises**.  
3. Follow along sequentially for a complete ML learning experience.  

---

## üèÜ Goal
By completing this course, you will gain strong foundations in **Machine Learning** with hands-on projects and intuition, math, and coding experience.

